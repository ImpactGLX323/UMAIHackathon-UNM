{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7174ef0c-8b52-4e81-a9e6-1db9654284d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e67dd0c7-836a-4758-88a0-dfbcb9483052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed dataset\n",
    "df = pd.read_csv('../data/preprocessed/with_diabetes_status/dataset_with_diabetes_status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f23dd21-cf59-40ce-9af2-59a380503486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate records\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87f5637-0a4b-4e54-9206-947902ae5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the diabetes and hba1c columns\n",
    "df = df.drop('diabetes', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf99c8c-45a7-4ff4-9b74-2895222f82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records where gender is 'Other'\n",
    "df = df[df['gender'] != 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c77cf5-137a-469a-9317-790e7ca611f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>diabetes_status</th>\n",
       "      <th>blood_glucose_level_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>stress induced type 2 diabetic</td>\n",
       "      <td>4.941642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>stress induced type 2 diabetic</td>\n",
       "      <td>4.382027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>stress induced prediabetic</td>\n",
       "      <td>5.062595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>non diabetic</td>\n",
       "      <td>5.043425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>non diabetic</td>\n",
       "      <td>5.043425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>24.60</td>\n",
       "      <td>4.8</td>\n",
       "      <td>non diabetic</td>\n",
       "      <td>4.976734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>stress induced type 2 diabetic</td>\n",
       "      <td>4.605170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>stress induced prediabetic</td>\n",
       "      <td>5.043425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>non diabetic</td>\n",
       "      <td>4.605170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Female</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>stress induced type 2 diabetic</td>\n",
       "      <td>4.499810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96128 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0      Female  80.0             0              1           never  25.19   \n",
       "1      Female  54.0             0              0         No Info  27.32   \n",
       "2        Male  28.0             0              0           never  27.32   \n",
       "3      Female  36.0             0              0         current  23.45   \n",
       "4        Male  76.0             1              1         current  20.14   \n",
       "...       ...   ...           ...            ...             ...    ...   \n",
       "99994  Female  36.0             0              0         No Info  24.60   \n",
       "99996  Female   2.0             0              0         No Info  17.37   \n",
       "99997    Male  66.0             0              0          former  27.83   \n",
       "99998  Female  24.0             0              0           never  35.42   \n",
       "99999  Female  57.0             0              0         current  22.43   \n",
       "\n",
       "       HbA1c_level                 diabetes_status  blood_glucose_level_log  \n",
       "0              6.6  stress induced type 2 diabetic                 4.941642  \n",
       "1              6.6  stress induced type 2 diabetic                 4.382027  \n",
       "2              5.7      stress induced prediabetic                 5.062595  \n",
       "3              5.0                    non diabetic                 5.043425  \n",
       "4              4.8                    non diabetic                 5.043425  \n",
       "...            ...                             ...                      ...  \n",
       "99994          4.8                    non diabetic                 4.976734  \n",
       "99996          6.5  stress induced type 2 diabetic                 4.605170  \n",
       "99997          5.7      stress induced prediabetic                 5.043425  \n",
       "99998          4.0                    non diabetic                 4.605170  \n",
       "99999          6.6  stress induced type 2 diabetic                 4.499810  \n",
       "\n",
       "[96128 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of columns to transform\n",
    "columns_to_transform = ['blood_glucose_level']\n",
    "\n",
    "# Apply log transformation and create new columns with a '_log' suffix\n",
    "for col in columns_to_transform:\n",
    "    # Check for zero or negative values\n",
    "    if (df[col] <= 0).any():\n",
    "        df[col + '_log'] = np.log1p(df[col])\n",
    "    else:\n",
    "        df[col + '_log'] = np.log(df[col])\n",
    "\n",
    "# Drop the original columns\n",
    "df.drop(columns=columns_to_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f491662-7eb6-4643-abde-c53aaacdb82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "df = pd.get_dummies(df, columns=['gender', 'smoking_history'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d9f0889-0056-483c-9d10-953c77570bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order of categories for diabetes_status\n",
    "status_order = ['non diabetic', 'stress induced prediabetic', 'stress induced type 2 diabetic', 'prediabetic', 'diabetic']\n",
    "\n",
    "# Create a mapping for the specified order\n",
    "status_mapping = {status: i for i, status in enumerate(status_order)}\n",
    "\n",
    "# Map 'diabetes_status' to the numeric encoding\n",
    "df['diabetes_status'] = df['diabetes_status'].map(status_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40a6a15a-8a16-4d1f-913a-83f84476cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the encoded 'diabetes_status' to the right\n",
    "cols = df.columns.tolist()\n",
    "cols.append(cols.pop(cols.index('diabetes_status')))\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab843434-f8f3-4113-af8e-e1d0328c92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns=['diabetes_status'])\n",
    "y = df['diabetes_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c77b7d3-055d-42cf-80ee-fca1cf1009f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0586de8-b790-4d03-8eb3-0ae55d6fc3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e45f658c-ef1c-4409-b707-f46f27e269cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to evaluate (only classification models for multi-class target)\n",
    "models = [\n",
    "    StackingClassifier(\n",
    "        estimators=[\n",
    "            ('bagging', BaggingClassifier()),\n",
    "            ('hist_grad', HistGradientBoostingClassifier()),\n",
    "            ('rf', RandomForestClassifier())\n",
    "        ],\n",
    "        final_estimator=LogisticRegression()\n",
    "    ),\n",
    "    StackingClassifier(\n",
    "        estimators=[\n",
    "            ('bagging', BaggingClassifier()),\n",
    "            ('hist_grad', HistGradientBoostingClassifier()),\n",
    "            ('rf', RandomForestClassifier())\n",
    "        ],\n",
    "        final_estimator=RidgeClassifier()\n",
    "    ),\n",
    "    StackingClassifier(\n",
    "        estimators=[\n",
    "            ('bagging', BaggingClassifier()),\n",
    "            ('hist_grad', HistGradientBoostingClassifier()),\n",
    "            ('rf', RandomForestClassifier())\n",
    "        ],\n",
    "        final_estimator=SVC(probability=True)\n",
    "    ),\n",
    "    StackingClassifier(\n",
    "        estimators=[\n",
    "            ('bagging', BaggingClassifier()),\n",
    "            ('hist_grad', HistGradientBoostingClassifier()),\n",
    "            ('rf', RandomForestClassifier())\n",
    "        ],\n",
    "        final_estimator=KNeighborsClassifier()\n",
    "    ),\n",
    "    StackingClassifier(\n",
    "        estimators=[\n",
    "            ('bagging', BaggingClassifier()),\n",
    "            ('hist_grad', HistGradientBoostingClassifier()),\n",
    "            ('rf', RandomForestClassifier())\n",
    "        ],\n",
    "        final_estimator=GaussianNB()\n",
    "    ),\n",
    "    StackingClassifier(\n",
    "        estimators=[\n",
    "            ('bagging', BaggingClassifier()),\n",
    "            ('hist_grad', HistGradientBoostingClassifier()),\n",
    "            ('rf', RandomForestClassifier())\n",
    "        ],\n",
    "        final_estimator=RandomForestClassifier()\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb9ca292-0dfd-40f5-848c-59a1e95e31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, X, y, kf):\n",
    "    results = {}\n",
    "    \n",
    "    for model in models:\n",
    "        model_name = type(model).__name__\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        \n",
    "        fold_accuracies = []\n",
    "        fold_f1_scores = []\n",
    "        fold_reports = []\n",
    "        \n",
    "        for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            report = classification_report(y_test, y_pred)\n",
    "            \n",
    "            fold_accuracies.append(accuracy)\n",
    "            fold_f1_scores.append(f1)\n",
    "            fold_reports.append(report)\n",
    "            \n",
    "            print(f\"Fold {fold + 1} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
    "            print(f\"Classification Report for Fold {fold + 1}:\\n{report}\\n\")\n",
    "        \n",
    "        mean_accuracy = np.mean(fold_accuracies)\n",
    "        std_accuracy = np.std(fold_accuracies)\n",
    "        mean_f1 = np.mean(fold_f1_scores)\n",
    "        std_f1 = np.std(fold_f1_scores)\n",
    "        \n",
    "        print(f\"\\n{model_name} - Mean Accuracy: {mean_accuracy:.4f} (Â± {std_accuracy:.4f}), Mean F1 Score: {mean_f1:.4f} (Â± {std_f1:.4f})\\n\")\n",
    "        \n",
    "        results[model_name] = {\n",
    "            'mean_accuracy': mean_accuracy,\n",
    "            'std_accuracy': std_accuracy,\n",
    "            'mean_f1': mean_f1,\n",
    "            'std_f1': std_f1,\n",
    "            'reports': fold_reports\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d0ffe84-99e4-4b16-b9fc-71b9ead8d30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating StackingClassifier...\n",
      "Fold 1 - Accuracy: 0.9799, F1 Score: 0.9799\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7407\n",
      "           1       0.96      0.98      0.97      7227\n",
      "           2       0.97      0.99      0.98      7174\n",
      "           3       0.98      0.96      0.97      7335\n",
      "           4       0.99      0.97      0.98      7324\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 2 - Accuracy: 0.9792, F1 Score: 0.9792\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7175\n",
      "           1       0.96      0.97      0.97      7402\n",
      "           2       0.98      0.99      0.98      7231\n",
      "           3       0.97      0.96      0.97      7322\n",
      "           4       0.99      0.98      0.98      7337\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 3 - Accuracy: 0.9807, F1 Score: 0.9807\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7208\n",
      "           1       0.96      0.98      0.97      7291\n",
      "           2       0.98      0.99      0.98      7448\n",
      "           3       0.98      0.96      0.97      7216\n",
      "           4       0.99      0.98      0.98      7304\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 4 - Accuracy: 0.9806, F1 Score: 0.9806\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7285\n",
      "           1       0.96      0.98      0.97      7366\n",
      "           2       0.97      0.99      0.98      7331\n",
      "           3       0.98      0.96      0.97      7267\n",
      "           4       0.99      0.97      0.98      7218\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 5 - Accuracy: 0.9791, F1 Score: 0.9791\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7392\n",
      "           1       0.96      0.98      0.97      7181\n",
      "           2       0.97      0.99      0.98      7283\n",
      "           3       0.98      0.96      0.97      7327\n",
      "           4       0.99      0.97      0.98      7284\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "\n",
      "StackingClassifier - Mean Accuracy: 0.9799 (Â± 0.0007), Mean F1 Score: 0.9799 (Â± 0.0007)\n",
      "\n",
      "Evaluating StackingClassifier...\n",
      "Fold 1 - Accuracy: 0.9806, F1 Score: 0.9806\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7407\n",
      "           1       0.96      0.99      0.97      7227\n",
      "           2       0.97      0.99      0.98      7174\n",
      "           3       0.99      0.96      0.97      7335\n",
      "           4       0.99      0.97      0.98      7324\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 2 - Accuracy: 0.9799, F1 Score: 0.9799\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7175\n",
      "           1       0.96      0.98      0.97      7402\n",
      "           2       0.97      0.99      0.98      7231\n",
      "           3       0.98      0.96      0.97      7322\n",
      "           4       0.99      0.97      0.98      7337\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 3 - Accuracy: 0.9805, F1 Score: 0.9805\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7208\n",
      "           1       0.96      0.98      0.97      7291\n",
      "           2       0.97      0.99      0.98      7448\n",
      "           3       0.98      0.95      0.97      7216\n",
      "           4       0.99      0.97      0.98      7304\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 4 - Accuracy: 0.9809, F1 Score: 0.9809\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7285\n",
      "           1       0.96      0.99      0.97      7366\n",
      "           2       0.97      0.99      0.98      7331\n",
      "           3       0.98      0.96      0.97      7267\n",
      "           4       0.99      0.97      0.98      7218\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 5 - Accuracy: 0.9803, F1 Score: 0.9803\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7392\n",
      "           1       0.96      0.98      0.97      7181\n",
      "           2       0.97      0.99      0.98      7283\n",
      "           3       0.98      0.96      0.97      7327\n",
      "           4       0.99      0.97      0.98      7284\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "\n",
      "StackingClassifier - Mean Accuracy: 0.9805 (Â± 0.0003), Mean F1 Score: 0.9805 (Â± 0.0003)\n",
      "\n",
      "Evaluating StackingClassifier...\n",
      "Fold 1 - Accuracy: 0.9807, F1 Score: 0.9807\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7407\n",
      "           1       0.95      0.99      0.97      7227\n",
      "           2       0.96      0.99      0.98      7174\n",
      "           3       0.99      0.95      0.97      7335\n",
      "           4       0.99      0.96      0.98      7324\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 2 - Accuracy: 0.9803, F1 Score: 0.9803\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7175\n",
      "           1       0.95      0.99      0.97      7402\n",
      "           2       0.97      0.99      0.98      7231\n",
      "           3       0.99      0.95      0.97      7322\n",
      "           4       0.99      0.97      0.98      7337\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 3 - Accuracy: 0.9803, F1 Score: 0.9802\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7208\n",
      "           1       0.95      0.99      0.97      7291\n",
      "           2       0.97      1.00      0.98      7448\n",
      "           3       0.99      0.95      0.97      7216\n",
      "           4       1.00      0.97      0.98      7304\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 4 - Accuracy: 0.9803, F1 Score: 0.9802\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7285\n",
      "           1       0.95      0.99      0.97      7366\n",
      "           2       0.97      0.99      0.98      7331\n",
      "           3       0.99      0.95      0.97      7267\n",
      "           4       0.99      0.97      0.98      7218\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 5 - Accuracy: 0.9809, F1 Score: 0.9809\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7392\n",
      "           1       0.95      0.99      0.97      7181\n",
      "           2       0.97      1.00      0.98      7283\n",
      "           3       0.99      0.95      0.97      7327\n",
      "           4       1.00      0.97      0.98      7284\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "\n",
      "StackingClassifier - Mean Accuracy: 0.9805 (Â± 0.0002), Mean F1 Score: 0.9805 (Â± 0.0003)\n",
      "\n",
      "Evaluating StackingClassifier...\n",
      "Fold 1 - Accuracy: 0.9786, F1 Score: 0.9786\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7407\n",
      "           1       0.95      0.99      0.97      7227\n",
      "           2       0.97      0.99      0.98      7174\n",
      "           3       0.99      0.95      0.97      7335\n",
      "           4       0.99      0.97      0.98      7324\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 2 - Accuracy: 0.9780, F1 Score: 0.9780\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7175\n",
      "           1       0.95      0.98      0.97      7402\n",
      "           2       0.97      0.99      0.98      7231\n",
      "           3       0.98      0.95      0.97      7322\n",
      "           4       0.99      0.97      0.98      7337\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 3 - Accuracy: 0.9777, F1 Score: 0.9777\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7208\n",
      "           1       0.95      0.98      0.97      7291\n",
      "           2       0.97      0.99      0.98      7448\n",
      "           3       0.98      0.95      0.96      7216\n",
      "           4       0.99      0.97      0.98      7304\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 4 - Accuracy: 0.9787, F1 Score: 0.9787\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7285\n",
      "           1       0.95      0.99      0.97      7366\n",
      "           2       0.97      0.99      0.98      7331\n",
      "           3       0.98      0.95      0.97      7267\n",
      "           4       0.99      0.97      0.98      7218\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 5 - Accuracy: 0.9786, F1 Score: 0.9786\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7392\n",
      "           1       0.95      0.99      0.97      7181\n",
      "           2       0.97      0.99      0.98      7283\n",
      "           3       0.99      0.95      0.97      7327\n",
      "           4       0.99      0.97      0.98      7284\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "\n",
      "StackingClassifier - Mean Accuracy: 0.9783 (Â± 0.0004), Mean F1 Score: 0.9783 (Â± 0.0004)\n",
      "\n",
      "Evaluating StackingClassifier...\n",
      "Fold 1 - Accuracy: 0.9769, F1 Score: 0.9769\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7407\n",
      "           1       0.97      0.96      0.96      7227\n",
      "           2       0.97      0.98      0.98      7174\n",
      "           3       0.96      0.97      0.96      7335\n",
      "           4       0.98      0.97      0.98      7324\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 2 - Accuracy: 0.9778, F1 Score: 0.9778\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7175\n",
      "           1       0.96      0.97      0.97      7402\n",
      "           2       0.97      0.98      0.98      7231\n",
      "           3       0.97      0.96      0.97      7322\n",
      "           4       0.98      0.97      0.98      7337\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 3 - Accuracy: 0.9800, F1 Score: 0.9800\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7208\n",
      "           1       0.96      0.98      0.97      7291\n",
      "           2       0.98      0.99      0.98      7448\n",
      "           3       0.98      0.96      0.97      7216\n",
      "           4       0.99      0.98      0.98      7304\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 4 - Accuracy: 0.9812, F1 Score: 0.9812\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7285\n",
      "           1       0.96      0.98      0.97      7366\n",
      "           2       0.98      0.99      0.98      7331\n",
      "           3       0.98      0.96      0.97      7267\n",
      "           4       0.99      0.98      0.98      7218\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 5 - Accuracy: 0.9797, F1 Score: 0.9797\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7392\n",
      "           1       0.96      0.98      0.97      7181\n",
      "           2       0.97      0.99      0.98      7283\n",
      "           3       0.98      0.96      0.97      7327\n",
      "           4       0.99      0.97      0.98      7284\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "\n",
      "StackingClassifier - Mean Accuracy: 0.9791 (Â± 0.0015), Mean F1 Score: 0.9791 (Â± 0.0015)\n",
      "\n",
      "Evaluating StackingClassifier...\n",
      "Fold 1 - Accuracy: 0.9808, F1 Score: 0.9808\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7407\n",
      "           1       0.95      0.99      0.97      7227\n",
      "           2       0.97      0.99      0.98      7174\n",
      "           3       0.99      0.95      0.97      7335\n",
      "           4       0.99      0.97      0.98      7324\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 2 - Accuracy: 0.9795, F1 Score: 0.9795\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7175\n",
      "           1       0.95      0.99      0.97      7402\n",
      "           2       0.97      0.99      0.98      7231\n",
      "           3       0.99      0.94      0.97      7322\n",
      "           4       0.99      0.97      0.98      7337\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 3 - Accuracy: 0.9801, F1 Score: 0.9801\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7208\n",
      "           1       0.95      1.00      0.97      7291\n",
      "           2       0.97      0.99      0.98      7448\n",
      "           3       1.00      0.94      0.97      7216\n",
      "           4       0.99      0.97      0.98      7304\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 4 - Accuracy: 0.9807, F1 Score: 0.9807\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7285\n",
      "           1       0.95      0.99      0.97      7366\n",
      "           2       0.97      0.99      0.98      7331\n",
      "           3       0.99      0.95      0.97      7267\n",
      "           4       0.99      0.97      0.98      7218\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "Fold 5 - Accuracy: 0.9810, F1 Score: 0.9810\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7392\n",
      "           1       0.95      1.00      0.97      7181\n",
      "           2       0.97      0.99      0.98      7283\n",
      "           3       1.00      0.95      0.97      7327\n",
      "           4       0.99      0.97      0.98      7284\n",
      "\n",
      "    accuracy                           0.98     36467\n",
      "   macro avg       0.98      0.98      0.98     36467\n",
      "weighted avg       0.98      0.98      0.98     36467\n",
      "\n",
      "\n",
      "\n",
      "StackingClassifier - Mean Accuracy: 0.9804 (Â± 0.0005), Mean F1 Score: 0.9804 (Â± 0.0005)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function with the updated list of models, features, target, and KFold object\n",
    "results = evaluate_models(models, X_res, y_res, kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f61d0cc-9828-4432-bca3-2ef107f03daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stacking_classifier.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model\n",
    "import joblib\n",
    "\n",
    "stacking_clf = models[5]\n",
    "joblib.dump(stacking_clf, 'stacking_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3b22f05-499d-40f7-b7e0-2b023af2db55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187c1bb-93f8-41f0-98ea-0e7b8b51786d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
