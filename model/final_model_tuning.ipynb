{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "684862e9-0712-4f70-9868-feadef9ff259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters found:\n",
      "  bagging__max_samples: 0.7475884550556351\n",
      "  bagging__n_estimators: 184\n",
      "  final_estimator__C: 1.833646535077721\n",
      "  final_estimator__degree: 2\n",
      "  final_estimator__kernel: 'poly'\n",
      "  hist_grad__learning_rate: 0.0646708263364187\n",
      "  hist_grad__max_iter: 181\n",
      "  rf__max_depth: 4\n",
      "  rf__n_estimators: 183\n",
      "\n",
      "Best weighted窶色1: 0.9796\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Load the processed dataset\n",
    "df = pd.read_csv('../data/preprocessed/with_diabetes_status/dataset_with_diabetes_status.csv')\n",
    "\n",
    "# Drop duplicate records\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Drop the diabetes and hba1c columns\n",
    "df = df.drop('diabetes', axis=1)\n",
    "\n",
    "# Drop records where gender is 'Other'\n",
    "df = df[df['gender'] != 'Other']\n",
    "\n",
    "# List of columns to transform\n",
    "columns_to_transform = ['blood_glucose_level']\n",
    "\n",
    "# Apply log transformation and create new columns with a '_log' suffix\n",
    "for col in columns_to_transform:\n",
    "    # Check for zero or negative values\n",
    "    if (df[col] <= 0).any():\n",
    "        df[col + '_log'] = np.log1p(df[col])\n",
    "    else:\n",
    "        df[col + '_log'] = np.log(df[col])\n",
    "\n",
    "# Drop the original columns\n",
    "df.drop(columns=columns_to_transform)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "df = pd.get_dummies(df, columns=['gender', 'smoking_history'], drop_first=False)\n",
    "\n",
    "# Define the order of categories for diabetes_status\n",
    "status_order = ['non diabetic', 'stress induced prediabetic', 'stress induced type 2 diabetic', 'prediabetic', 'diabetic']\n",
    "\n",
    "# Create a mapping for the specified order\n",
    "status_mapping = {status: i for i, status in enumerate(status_order)}\n",
    "\n",
    "# Map 'diabetes_status' to the numeric encoding\n",
    "df['diabetes_status'] = df['diabetes_status'].map(status_mapping)\n",
    "\n",
    "# Move the encoded 'diabetes_status' to the right\n",
    "cols = df.columns.tolist()\n",
    "cols.append(cols.pop(cols.index('diabetes_status')))\n",
    "df = df[cols]\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['diabetes_status'])\n",
    "y = df['diabetes_status']\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# defining stacking classifier\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('bagging', BaggingClassifier(random_state=42)),\n",
    "        ('hist_grad', HistGradientBoostingClassifier(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42))\n",
    "    ],\n",
    "    final_estimator=SVC(probability=True, random_state=42),\n",
    "    cv=3,          # internal cv for stacking folds\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# defining hyperparameter distributions\n",
    "param_dist = {\n",
    "    # BaggingClassifier params\n",
    "    'bagging__n_estimators': randint(10, 200),\n",
    "    'bagging__max_samples': uniform(0.5, 0.5),\n",
    "    # HistGradientBoostingClassifier params\n",
    "    'hist_grad__max_iter': randint(50, 300),\n",
    "    'hist_grad__learning_rate': uniform(0.01, 0.3),\n",
    "    # RandomForestClassifier params\n",
    "    'rf__n_estimators': randint(50, 300),\n",
    "    'rf__max_depth': randint(3, 20),\n",
    "    # final SVC meta窶親stimator params\n",
    "    'final_estimator__C': uniform(0.1, 10),\n",
    "    'final_estimator__kernel': ['rbf', 'poly'],\n",
    "    'final_estimator__degree': randint(2,5)\n",
    "}\n",
    "\n",
    "# setting up RandomizedSearchCV\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=stack,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,                    # number of random draws\n",
    "    scoring=['accuracy','f1_weighted'],\n",
    "    refit='f1_weighted',          # final refit uses weighted窶色1\n",
    "    cv=kf,                        # outer KFold\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# run the search on resampled data\n",
    "search.fit(X_res, y_res)\n",
    "\n",
    "# print out the best parameters and corresponding scores\n",
    "print(\"Best parameters found:\")\n",
    "for param, val in search.best_params_.items():\n",
    "    print(f\"  {param}: {val!r}\")\n",
    "\n",
    "print(f\"\\nBest weighted窶色1: {search.best_score_:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
